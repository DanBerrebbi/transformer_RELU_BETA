[2021-04-22_13:35:21.613] INFO Options = {'prog': '/nfs/RESEARCH/berrebbi/git/transformer_serie_2/minmt-train.py', 'dnet': '/nfs/RESEARCH/berrebbi/git/transformer_serie_2/model_serie_plein', 'src_train': 'data_corpus/trn_src_plein', 'tgt_train': 'data_corpus/trn_tgt_plein', 'src_valid': 'data_corpus/val_src_plein', 'tgt_valid': 'data_corpus/val_tgt_plein', 'max_steps': 450000, 'max_epochs': 0, 'validate_every': 5000, 'save_every': 5000, 'report_every': 100, 'keep_last_n': 5, 'mask_prefix': False, 'noam_scale': 2.0, 'noam_warmup': 4000, 'label_smoothing': 0.1, 'loss': 'KLDiv', 'clip': 0.5, 'shard_size': 500000, 'max_length': 100, 'batch_size': 4096, 'batch_type': 'tokens', 'cuda': True, 'seed': 12345, 'sim_train': 'data_corpus/trn_sim_plein', 'pre_train': 'data_corpus/trn_pre_plein', 'sim_valid': 'data_corpus/val_sim_plein', 'pre_valid': 'data_corpus/val_pre_plein'}
[2021-04-22_13:35:21.615] INFO Network = {'emb_dim': 512, 'qk_dim': 64, 'v_dim': 64, 'ff_dim': 2048, 'n_heads': 8, 'n_layers': 6, 'dropout': 0.1, 'share_embeddings': False, 'weight_decay': 0.0, 'beta1': 0.9, 'beta2': 0.998, 'eps': 1e-09}
[2021-04-22_13:35:29.070] INFO Built model (#params, size) = (182852864, 697.53MB) in device cuda:0
[2021-04-22_13:35:29.901] INFO Loaded model/optimizer step=0 from /nfs/RESEARCH/berrebbi/git/transformer_serie_2/model_serie_plein/network.checkpoint_00000000.pt
[2021-04-22_13:35:30.003] INFO Read Corpus (7006 lines ~ 7006 tokens ~ 0 OOVs [0.00%]) from data_corpus/val_src_plein
[2021-04-22_13:35:30.124] INFO Read Corpus (7006 lines ~ 14012 tokens ~ 0 OOVs [0.00%]) from data_corpus/val_tgt_plein
[2021-04-22_13:35:30.236] INFO Read Corpus (7006 lines ~ 21018 tokens ~ 0 OOVs [0.00%]) from data_corpus/val_sim_plein
[2021-04-22_13:35:30.368] INFO Read Corpus (7006 lines ~ 28024 tokens ~ 0 OOVs [0.00%]) from data_corpus/val_pre_plein
[2021-04-22_13:36:42.689] INFO Read Corpus (3558988 lines ~ 3558988 tokens ~ 0 OOVs [0.00%]) from data_corpus/trn_src_plein
[2021-04-22_13:38:00.716] INFO Read Corpus (3558988 lines ~ 7117976 tokens ~ 0 OOVs [0.00%]) from data_corpus/trn_tgt_plein
[2021-04-22_13:39:20.385] INFO Read Corpus (3558988 lines ~ 10676964 tokens ~ 0 OOVs [0.00%]) from data_corpus/trn_sim_plein
[2021-04-22_13:40:44.201] INFO Read Corpus (3558988 lines ~ 14235952 tokens ~ 0 OOVs [0.00%]) from data_corpus/trn_pre_plein
[2021-04-22_13:40:44.222] INFO Running: learning
[2021-04-22_13:40:44.222] INFO Epoch 1
[2021-04-22_13:40:47.914] INFO Built shard 1/8 (490459 examples)
[2021-04-22_13:40:53.275] INFO Built 8606 batchs in shard
[2021-04-22_13:41:38.478] INFO n_msk: 3795 acc_msk: 0.00
[2021-04-22_13:41:38.482] INFO Learning step: 100 epoch: 1 batch: 100 steps/sec: 1.84 lr: 0.000035 Loss: 8.525
[2021-04-22_13:42:23.069] INFO n_msk: 3923 acc_msk: 0.00
[2021-04-22_13:42:23.074] INFO Learning step: 200 epoch: 1 batch: 200 steps/sec: 2.24 lr: 0.000070 Loss: 7.110
[2021-04-22_13:43:07.135] INFO n_msk: 3689 acc_msk: 7.92
[2021-04-22_13:43:07.139] INFO Learning step: 300 epoch: 1 batch: 300 steps/sec: 2.27 lr: 0.000105 Loss: 6.145
[2021-04-22_13:43:52.266] INFO n_msk: 3762 acc_msk: 36.82
[2021-04-22_13:43:52.270] INFO Learning step: 400 epoch: 1 batch: 400 steps/sec: 2.22 lr: 0.000140 Loss: 5.767
[2021-04-22_13:44:38.222] INFO n_msk: 4091 acc_msk: 51.23
[2021-04-22_13:44:38.228] INFO Learning step: 500 epoch: 1 batch: 500 steps/sec: 2.18 lr: 0.000175 Loss: 5.327
[2021-04-22_13:45:23.722] INFO n_msk: 3766 acc_msk: 55.39
[2021-04-22_13:45:23.728] INFO Learning step: 600 epoch: 1 batch: 600 steps/sec: 2.20 lr: 0.000210 Loss: 4.985
[2021-04-22_13:46:08.400] INFO n_msk: 3912 acc_msk: 60.38
[2021-04-22_13:46:08.405] INFO Learning step: 700 epoch: 1 batch: 700 steps/sec: 2.24 lr: 0.000245 Loss: 4.720
[2021-04-22_13:46:52.514] INFO n_msk: 3785 acc_msk: 59.10
[2021-04-22_13:46:52.520] INFO Learning step: 800 epoch: 1 batch: 800 steps/sec: 2.27 lr: 0.000280 Loss: 4.477
[2021-04-22_13:47:36.852] INFO n_msk: 3869 acc_msk: 63.58
[2021-04-22_13:47:36.857] INFO Learning step: 900 epoch: 1 batch: 900 steps/sec: 2.26 lr: 0.000314 Loss: 4.299
[2021-04-22_13:48:21.729] INFO n_msk: 3860 acc_msk: 63.24
[2021-04-22_13:48:21.733] INFO Learning step: 1000 epoch: 1 batch: 1000 steps/sec: 2.23 lr: 0.000349 Loss: 4.142
[2021-04-22_13:49:06.315] INFO n_msk: 3878 acc_msk: 65.01
[2021-04-22_13:49:06.320] INFO Learning step: 1100 epoch: 1 batch: 1100 steps/sec: 2.24 lr: 0.000384 Loss: 3.961
[2021-04-22_13:49:51.833] INFO n_msk: 3907 acc_msk: 63.27
[2021-04-22_13:49:51.838] INFO Learning step: 1200 epoch: 1 batch: 1200 steps/sec: 2.20 lr: 0.000419 Loss: 3.855
[2021-04-22_13:50:36.620] INFO n_msk: 3916 acc_msk: 67.82
[2021-04-22_13:50:36.625] INFO Learning step: 1300 epoch: 1 batch: 1300 steps/sec: 2.23 lr: 0.000454 Loss: 3.750
[2021-04-22_13:51:22.620] INFO n_msk: 4028 acc_msk: 67.63
[2021-04-22_13:51:22.626] INFO Learning step: 1400 epoch: 1 batch: 1400 steps/sec: 2.17 lr: 0.000489 Loss: 3.656
[2021-04-22_13:52:07.110] INFO n_msk: 3758 acc_msk: 70.30
[2021-04-22_13:52:07.115] INFO Learning step: 1500 epoch: 1 batch: 1500 steps/sec: 2.25 lr: 0.000524 Loss: 3.571
[2021-04-22_13:52:53.793] INFO n_msk: 3931 acc_msk: 67.72
[2021-04-22_13:52:53.798] INFO Learning step: 1600 epoch: 1 batch: 1600 steps/sec: 2.14 lr: 0.000559 Loss: 3.524
[2021-04-22_13:53:40.546] INFO n_msk: 3827 acc_msk: 69.58
[2021-04-22_13:53:40.553] INFO Learning step: 1700 epoch: 1 batch: 1700 steps/sec: 2.14 lr: 0.000594 Loss: 3.429
[2021-04-22_13:54:26.317] INFO n_msk: 3886 acc_msk: 70.38
[2021-04-22_13:54:26.322] INFO Learning step: 1800 epoch: 1 batch: 1800 steps/sec: 2.19 lr: 0.000629 Loss: 3.353
[2021-04-22_13:55:10.160] INFO n_msk: 3912 acc_msk: 69.40
[2021-04-22_13:55:10.945] INFO Learning step: 1900 epoch: 1 batch: 1900 steps/sec: 2.28 lr: 0.000664 Loss: 3.284
[2021-04-22_13:55:56.435] INFO n_msk: 4043 acc_msk: 70.20
[2021-04-22_13:55:56.441] INFO Learning step: 2000 epoch: 1 batch: 2000 steps/sec: 2.20 lr: 0.000699 Loss: 3.220
[2021-04-22_13:56:41.919] INFO n_msk: 3900 acc_msk: 69.59
[2021-04-22_13:56:41.926] INFO Learning step: 2100 epoch: 1 batch: 2100 steps/sec: 2.20 lr: 0.000734 Loss: 3.213
[2021-04-22_13:57:26.071] INFO n_msk: 4050 acc_msk: 71.06
[2021-04-22_13:57:26.078] INFO Learning step: 2200 epoch: 1 batch: 2200 steps/sec: 2.27 lr: 0.000769 Loss: 3.132
[2021-04-22_13:58:10.839] INFO n_msk: 3779 acc_msk: 70.71
[2021-04-22_13:58:10.845] INFO Learning step: 2300 epoch: 1 batch: 2300 steps/sec: 2.23 lr: 0.000804 Loss: 3.121
[2021-04-22_13:58:56.546] INFO n_msk: 3749 acc_msk: 69.59
[2021-04-22_13:58:56.552] INFO Learning step: 2400 epoch: 1 batch: 2400 steps/sec: 2.19 lr: 0.000839 Loss: 3.111
[2021-04-22_13:59:41.942] INFO n_msk: 3889 acc_msk: 73.82
[2021-04-22_13:59:41.947] INFO Learning step: 2500 epoch: 1 batch: 2500 steps/sec: 2.20 lr: 0.000873 Loss: 3.007
[2021-04-22_14:00:27.118] INFO n_msk: 3728 acc_msk: 70.14
[2021-04-22_14:00:27.124] INFO Learning step: 2600 epoch: 1 batch: 2600 steps/sec: 2.21 lr: 0.000908 Loss: 3.064
[2021-04-22_14:01:12.927] INFO n_msk: 3603 acc_msk: 67.28
[2021-04-22_14:01:12.933] INFO Learning step: 2700 epoch: 1 batch: 2700 steps/sec: 2.18 lr: 0.000943 Loss: 2.984
[2021-04-22_14:01:58.581] INFO n_msk: 3878 acc_msk: 71.25
[2021-04-22_14:01:58.587] INFO Learning step: 2800 epoch: 1 batch: 2800 steps/sec: 2.19 lr: 0.000978 Loss: 2.963
[2021-04-22_14:02:44.171] INFO n_msk: 3816 acc_msk: 71.17
[2021-04-22_14:02:44.178] INFO Learning step: 2900 epoch: 1 batch: 2900 steps/sec: 2.19 lr: 0.001013 Loss: 2.974
[2021-04-22_14:03:28.797] INFO n_msk: 3830 acc_msk: 70.91
[2021-04-22_14:03:28.803] INFO Learning step: 3000 epoch: 1 batch: 3000 steps/sec: 2.24 lr: 0.001048 Loss: 2.913
[2021-04-22_14:04:16.299] INFO n_msk: 3957 acc_msk: 70.71
[2021-04-22_14:04:16.305] INFO Learning step: 3100 epoch: 1 batch: 3100 steps/sec: 2.11 lr: 0.001083 Loss: 2.922
[2021-04-22_14:05:01.591] INFO n_msk: 3807 acc_msk: 71.66
[2021-04-22_14:05:01.598] INFO Learning step: 3200 epoch: 1 batch: 3200 steps/sec: 2.21 lr: 0.001118 Loss: 2.878
[2021-04-22_14:05:48.035] INFO n_msk: 3807 acc_msk: 70.29
[2021-04-22_14:05:48.040] INFO Learning step: 3300 epoch: 1 batch: 3300 steps/sec: 2.15 lr: 0.001153 Loss: 2.879
[2021-04-22_14:06:34.673] INFO n_msk: 3763 acc_msk: 70.08
[2021-04-22_14:06:34.680] INFO Learning step: 3400 epoch: 1 batch: 3400 steps/sec: 2.14 lr: 0.001188 Loss: 2.871
[2021-04-22_14:07:20.001] INFO n_msk: 3951 acc_msk: 70.06
[2021-04-22_14:07:20.006] INFO Learning step: 3500 epoch: 1 batch: 3500 steps/sec: 2.21 lr: 0.001223 Loss: 2.826
[2021-04-22_14:08:04.500] INFO n_msk: 4188 acc_msk: 71.47
[2021-04-22_14:08:04.507] INFO Learning step: 3600 epoch: 1 batch: 3600 steps/sec: 2.25 lr: 0.001258 Loss: 2.828
[2021-04-22_14:08:50.292] INFO n_msk: 3811 acc_msk: 70.43
[2021-04-22_14:08:50.299] INFO Learning step: 3700 epoch: 1 batch: 3700 steps/sec: 2.18 lr: 0.001293 Loss: 2.810
[2021-04-22_14:09:35.392] INFO n_msk: 4000 acc_msk: 71.08
[2021-04-22_14:09:35.397] INFO Learning step: 3800 epoch: 1 batch: 3800 steps/sec: 2.22 lr: 0.001328 Loss: 2.762
[2021-04-22_14:10:20.073] INFO n_msk: 3837 acc_msk: 73.83
[2021-04-22_14:10:20.080] INFO Learning step: 3900 epoch: 1 batch: 3900 steps/sec: 2.24 lr: 0.001363 Loss: 2.757
[2021-04-22_14:11:04.116] INFO n_msk: 3794 acc_msk: 70.64
[2021-04-22_14:11:04.122] INFO Learning step: 4000 epoch: 1 batch: 4000 steps/sec: 2.27 lr: 0.001398 Loss: 2.767
[2021-04-22_14:11:49.236] INFO n_msk: 4034 acc_msk: 70.72
[2021-04-22_14:11:49.241] INFO Learning step: 4100 epoch: 1 batch: 4100 steps/sec: 2.22 lr: 0.001380 Loss: 2.816
[2021-04-22_14:12:34.488] INFO n_msk: 3899 acc_msk: 68.22
[2021-04-22_14:12:34.494] INFO Learning step: 4200 epoch: 1 batch: 4200 steps/sec: 2.21 lr: 0.001364 Loss: 2.816
[2021-04-22_14:13:18.986] INFO n_msk: 3930 acc_msk: 71.50
[2021-04-22_14:13:18.992] INFO Learning step: 4300 epoch: 1 batch: 4300 steps/sec: 2.25 lr: 0.001348 Loss: 2.735
[2021-04-22_14:14:04.411] INFO n_msk: 3903 acc_msk: 71.38
[2021-04-22_14:14:04.417] INFO Learning step: 4400 epoch: 1 batch: 4400 steps/sec: 2.20 lr: 0.001333 Loss: 2.782
[2021-04-22_14:14:46.480] INFO n_msk: 3726 acc_msk: 71.28
[2021-04-22_14:14:46.485] INFO Learning step: 4500 epoch: 1 batch: 4500 steps/sec: 2.38 lr: 0.001318 Loss: 2.798
[2021-04-22_14:15:29.737] INFO n_msk: 3932 acc_msk: 68.97
[2021-04-22_14:15:29.744] INFO Learning step: 4600 epoch: 1 batch: 4600 steps/sec: 2.31 lr: 0.001303 Loss: 2.697
[2021-04-22_14:16:12.001] INFO n_msk: 4155 acc_msk: 71.67
[2021-04-22_14:16:12.007] INFO Learning step: 4700 epoch: 1 batch: 4700 steps/sec: 2.37 lr: 0.001289 Loss: 2.687
[2021-04-22_14:16:56.889] INFO n_msk: 3931 acc_msk: 70.92
[2021-04-22_14:16:56.897] INFO Learning step: 4800 epoch: 1 batch: 4800 steps/sec: 2.23 lr: 0.001276 Loss: 2.686
[2021-04-22_14:17:43.611] INFO n_msk: 3786 acc_msk: 65.80
[2021-04-22_14:17:43.616] INFO Learning step: 4900 epoch: 1 batch: 4900 steps/sec: 2.14 lr: 0.001263 Loss: 2.771
[2021-04-22_14:18:29.477] INFO n_msk: 3809 acc_msk: 69.76
[2021-04-22_14:18:29.483] INFO Learning step: 5000 epoch: 1 batch: 5000 steps/sec: 2.18 lr: 0.001250 Loss: 2.646
[2021-04-22_14:18:29.505] INFO Built shard 1/1 (6811 examples)
[2021-04-22_14:18:29.567] INFO Built 108 batchs in shard
[2021-04-22_14:18:29.688] INFO POS: 1173
[2021-04-22_14:18:29.689] INFO SRC:   2   3063   72     6   1875   724   46   1550  6143  3171   470   57    308   51    675   16   3017   45     6    295  12327  366   39    210  2126  25043 3769   34   1526    9   2952   12    375  3108  3609   788    6    295  12327  85   1894   81     6    941  3002   479   205   277    6    295  12327 7157   72    16    428   16   1472   11    107  4147   12   4345  2377   84     3     0     0  
[2021-04-22_14:18:29.689] INFO TGT:   2    704   67    72    17    882    7   2007  1233   66    60    56    29   1319  10225  63   1975   54     7   3617  1308   164   10    295  12327 12623  681   72    23    53    40    471   209  1013  23228 28953 1072   36    17    685   19   2331    7    10   1526   19   3493   14    19   2130  1611   72    27   1194  3131  3098   43    10   2007  1324   18    10    295  12327  72    23    700   23    53    40    471   112  3714   14    209  3346  6434   84     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0  
[2021-04-22_14:18:29.689] INFO HYP:  139   67    72    17    882    7   2007   63    26    60    56    75   1498  1498   43    160   54     7   2687   17    26    10   1128  4708   14    352   19    20    700   40    471   20   3445  3445   14   1072   14    17    373   19   2130   14    15   1526   19   3493   14     7   3493   84    84     7    630   19     7    18    15   1816   84    18    10   1526  22576  84    274   700   10    700   40    471   10    453   19    10   2130    7    14     3    14    14    14    14    14    14    14    14     3     3     3     3     3     3     3     3     3  
[2021-04-22_14:18:29.689] INFO REF:  704   67    72    17    882    7   2007  1233   66    60    56    29   1319  10225  63   1975   54     7   3617  1308   164   10    295  12327 12623  681   72    23    53    40    471   209  1013  23228 28953 1072   36    17    685   19   2331    7    10   1526   19   3493   14    19   2130  1611   72    27   1194  3131  3098   43    10   2007  1324   18    10    295  12327  72    23    700   23    53    40    471   112  3714   14    209  3346  6434   84     3     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0  
[2021-04-22_14:18:40.622] INFO Validation step: 5000 #batchs: 108 sec: 11.14 loss: 2.167
[2021-04-22_14:35:16.846] INFO Saved /nfs/RESEARCH/berrebbi/git/transformer_serie_2/model_serie_plein/network.checkpoint_00005000.pt
[2021-04-22_14:36:02.783] INFO n_msk: 3754 acc_msk: 71.60
[2021-04-22_14:36:02.790] INFO Learning step: 5100 epoch: 1 batch: 5100 steps/sec: 0.09 lr: 0.001238 Loss: 2.680
[2021-04-22_14:36:48.997] INFO n_msk: 3813 acc_msk: 73.25
[2021-04-22_14:36:49.003] INFO Learning step: 5200 epoch: 1 batch: 5200 steps/sec: 2.16 lr: 0.001226 Loss: 2.613
[2021-04-22_14:37:33.942] INFO n_msk: 3862 acc_msk: 69.76
[2021-04-22_14:37:33.949] INFO Learning step: 5300 epoch: 1 batch: 5300 steps/sec: 2.23 lr: 0.001214 Loss: 2.676
[2021-04-22_14:38:19.656] INFO n_msk: 3914 acc_msk: 71.15
[2021-04-22_14:38:19.662] INFO Learning step: 5400 epoch: 1 batch: 5400 steps/sec: 2.19 lr: 0.001203 Loss: 2.618
[2021-04-22_14:39:04.341] INFO n_msk: 3682 acc_msk: 69.93
[2021-04-22_14:39:04.347] INFO Learning step: 5500 epoch: 1 batch: 5500 steps/sec: 2.24 lr: 0.001192 Loss: 2.690
[2021-04-22_14:39:49.028] INFO n_msk: 3826 acc_msk: 70.83
[2021-04-22_14:39:49.033] INFO Learning step: 5600 epoch: 1 batch: 5600 steps/sec: 2.24 lr: 0.001181 Loss: 2.684
[2021-04-22_14:40:33.028] INFO n_msk: 3887 acc_msk: 71.16
[2021-04-22_14:40:33.034] INFO Learning step: 5700 epoch: 1 batch: 5700 steps/sec: 2.27 lr: 0.001171 Loss: 2.632
[2021-04-22_14:41:18.379] INFO n_msk: 3772 acc_msk: 69.51
[2021-04-22_14:41:18.384] INFO Learning step: 5800 epoch: 1 batch: 5800 steps/sec: 2.21 lr: 0.001161 Loss: 2.741
[2021-04-22_14:42:02.808] INFO n_msk: 3939 acc_msk: 70.70
[2021-04-22_14:42:02.814] INFO Learning step: 5900 epoch: 1 batch: 5900 steps/sec: 2.25 lr: 0.001151 Loss: 2.632
[2021-04-22_14:42:48.774] INFO n_msk: 3909 acc_msk: 69.84
[2021-04-22_14:42:58.188] INFO Learning step: 6000 epoch: 1 batch: 6000 steps/sec: 2.18 lr: 0.001141 Loss: 2.719
[2021-04-22_14:43:43.618] INFO n_msk: 3879 acc_msk: 71.05
[2021-04-22_14:43:43.624] INFO Learning step: 6100 epoch: 1 batch: 6100 steps/sec: 2.20 lr: 0.001132 Loss: 2.615
[2021-04-22_14:44:31.466] INFO n_msk: 3790 acc_msk: 71.85
[2021-04-22_14:44:31.472] INFO Learning step: 6200 epoch: 1 batch: 6200 steps/sec: 2.09 lr: 0.001123 Loss: 2.622
[2021-04-22_14:45:16.945] INFO n_msk: 3730 acc_msk: 65.71
[2021-04-22_14:45:16.952] INFO Learning step: 6300 epoch: 1 batch: 6300 steps/sec: 2.20 lr: 0.001114 Loss: 2.645
[2021-04-22_14:46:01.923] INFO n_msk: 3929 acc_msk: 73.43
[2021-04-22_14:46:01.930] INFO Learning step: 6400 epoch: 1 batch: 6400 steps/sec: 2.22 lr: 0.001105 Loss: 2.575
[2021-04-22_14:46:47.006] INFO n_msk: 3886 acc_msk: 69.09
[2021-04-22_14:46:47.012] INFO Learning step: 6500 epoch: 1 batch: 6500 steps/sec: 2.22 lr: 0.001096 Loss: 2.648
[2021-04-22_14:47:32.466] INFO n_msk: 3818 acc_msk: 68.65
[2021-04-22_14:47:32.473] INFO Learning step: 6600 epoch: 1 batch: 6600 steps/sec: 2.20 lr: 0.001088 Loss: 2.686
[2021-04-22_14:48:17.522] INFO n_msk: 3773 acc_msk: 72.36
[2021-04-22_14:48:17.529] INFO Learning step: 6700 epoch: 1 batch: 6700 steps/sec: 2.22 lr: 0.001080 Loss: 2.634
[2021-04-22_14:49:03.663] INFO n_msk: 3737 acc_msk: 71.10
[2021-04-22_14:49:03.668] INFO Learning step: 6800 epoch: 1 batch: 6800 steps/sec: 2.17 lr: 0.001072 Loss: 2.659
[2021-04-22_14:49:50.336] INFO n_msk: 3879 acc_msk: 70.59
[2021-04-22_14:49:50.341] INFO Learning step: 6900 epoch: 1 batch: 6900 steps/sec: 2.14 lr: 0.001064 Loss: 2.642
[2021-04-22_14:50:36.483] INFO n_msk: 3912 acc_msk: 68.69
[2021-04-22_14:50:36.489] INFO Learning step: 7000 epoch: 1 batch: 7000 steps/sec: 2.17 lr: 0.001056 Loss: 2.649
[2021-04-22_14:51:21.798] INFO n_msk: 3822 acc_msk: 70.41
[2021-04-22_14:51:21.804] INFO Learning step: 7100 epoch: 1 batch: 7100 steps/sec: 2.21 lr: 0.001049 Loss: 2.638
[2021-04-22_14:52:06.914] INFO n_msk: 3885 acc_msk: 69.21
[2021-04-22_14:52:06.920] INFO Learning step: 7200 epoch: 1 batch: 7200 steps/sec: 2.22 lr: 0.001042 Loss: 2.648
[2021-04-22_14:52:53.078] INFO n_msk: 3906 acc_msk: 73.27
[2021-04-22_14:52:53.085] INFO Learning step: 7300 epoch: 1 batch: 7300 steps/sec: 2.17 lr: 0.001035 Loss: 2.614
[2021-04-22_14:53:37.171] INFO n_msk: 3926 acc_msk: 68.16
[2021-04-22_14:53:37.177] INFO Learning step: 7400 epoch: 1 batch: 7400 steps/sec: 2.27 lr: 0.001027 Loss: 2.668
[2021-04-22_14:54:21.747] INFO n_msk: 3641 acc_msk: 70.31
[2021-04-22_14:54:21.754] INFO Learning step: 7500 epoch: 1 batch: 7500 steps/sec: 2.24 lr: 0.001021 Loss: 2.670
[2021-04-22_14:55:07.080] INFO n_msk: 3871 acc_msk: 69.78
[2021-04-22_14:55:33.301] INFO Learning step: 7600 epoch: 1 batch: 7600 steps/sec: 2.21 lr: 0.001014 Loss: 2.638
